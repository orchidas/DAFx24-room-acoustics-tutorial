{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "\n",
    "from typing import Union, List, Tuple\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from loguru import logger\n",
    "from scipy.linalg import qr\n",
    "from scipy.fft import irfft, rfftfreq\n",
    "from IPython.display import Image, Audio\n",
    "from pathlib import Path\n",
    "\n",
    "from pyFDN.fdn import FDN\n",
    "from pyFDN.feedback_matrix import FeedbackMatrix, FeedbackMatrixType\n",
    "from pyFDN.delay_line import generate_coprime_delay_line_lengths\n",
    "from pyFDN.utils import ms_to_samps, estimate_echo_density, conv_binaural, interaural_coherence_menzer\n",
    "from pyFDN.sofa_parser import HRIRSOFAReader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "#### The structure of the generalised Feedback Delay Network is shown below. In this notebook, we will play with the parameters of the FDN, and listen to its output. We will also binauralise it using interaural coherence matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"../../resources/images/FDN_architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\boldsymbol{s}(n) & =\\boldsymbol{A} \\boldsymbol{s}(n-m)+\\boldsymbol{b} x(n) \\\\\n",
    "y(n) & =\\boldsymbol{c}^T \\boldsymbol{s}(n)+d x(n), \\\\\n",
    "\\boldsymbol{s}(n) & =\\left[s_1(n), s_2(n), \\ldots, s_N(n)\\right]^T \\\\\n",
    "\\boldsymbol{s}(n-m) & =\\left[s_1\\left(n-m_1\\right), s_2\\left(n-m_2\\right), \\ldots, s_N\\left(n-m_N\\right)\\right]^T\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Define FDN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling rate\n",
    "fs = 48000\n",
    "# number of delay lines\n",
    "N = 8\n",
    "frame_size = 2**8\n",
    "\n",
    "# we want a binaural output\n",
    "num_input = 1\n",
    "num_output = 2\n",
    "\n",
    "# input gains\n",
    "b = np.random.randn(N, num_input)\n",
    "# change coefficients of c so that the columns are orthonormal\n",
    "C_ortho = FeedbackMatrix.get_random_unitary_matrix(N)\n",
    "c = C_ortho[:, :num_output].T \n",
    "direct_gain = 0.5 * np.ones((num_output, num_input))\n",
    "\n",
    "# delay lengths should be co-prime\n",
    "# constrict delay range to be between 50 and 100ms\n",
    "delay_range_ms = np.array([50, 100])\n",
    "delay_lengths = generate_coprime_delay_line_lengths(delay_range_ms, N, fs)\n",
    "logger.info(f'The delay line lengths are {delay_lengths} samples')\n",
    "\n",
    "# how long should the impulse response be\n",
    "ir_len = ms_to_samps(300, fs)\n",
    "# create an impulse\n",
    "input_data = np.zeros((num_input, ir_len))\n",
    "input_data[:, 0] = 1.0\n",
    "\n",
    "# desired broadband T60\n",
    "des_t60_ms = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Plot FDN IR for a scalar feedback matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = FDN(fs, num_input, num_output, N, frame_size)\n",
    "fdn.init_io_gains(b, c)\n",
    "fdn.init_direct_gain(direct_gain)\n",
    "fdn.init_delay_line_lengths(delay_lengths)\n",
    "fdn.init_feedback_matrix()\n",
    "fdn.init_absorption_gains(des_t60_ms)\n",
    "fdn.init_delay_lines()\n",
    "\n",
    "sfm_fdn_ir = fdn.process(input_data)\n",
    "del fdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vector = np.arange(0, ir_len/fs, 1.0/fs)\n",
    "time_constant = (des_t60_ms*1e-3) / np.log(1000) \n",
    "exp_envelope = np.exp(-time_vector / time_constant)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time_vector, sfm_fdn_ir.T)\n",
    "plt.plot(time_vector, np.stack((exp_envelope, -exp_envelope), axis=-1), 'k--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(f'FDN IR with scalar feedback matrix and T60 of {des_t60_ms} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Plot FDN IR for a filter feedback matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = FDN(fs, num_input, num_output, N, frame_size)\n",
    "fdn.init_io_gains(b, c)\n",
    "fdn.init_direct_gain(direct_gain)\n",
    "fdn.init_delay_line_lengths(delay_lengths)\n",
    "fdn.init_feedback_matrix(FeedbackMatrixType.FILTER_VELVET, sparsity=0.2, num_mixing_stages=1)\n",
    "fdn.init_absorption_gains(des_t60_ms)\n",
    "fdn.init_delay_lines()\n",
    "\n",
    "vfm_fdn_ir = fdn.process(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(N, N, figsize=(12,12))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        ax[i,j].stem(fdn.feedback.feedback_matrix[i, j, :])\n",
    "        if j < N:\n",
    "            ax[i,j].set_xlabel('')\n",
    "        if i > 0:\n",
    "            ax[i,j].set_ylabel('')\n",
    "fig.suptitle(\"Velvet feedback matrix\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time_vector, vfm_fdn_ir.T)\n",
    "plt.plot(time_vector, np.stack((exp_envelope, -exp_envelope), axis=-1), 'k--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(f'FDN IR with velvet feedback matrix and T60 of {des_t60_ms} ms')\n",
    "\n",
    "del fdn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Compare the echo densities of the IRs with different feedback matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ned_sfm = estimate_echo_density(sfm_fdn_ir.T, fs)\n",
    "ned_vfm = estimate_echo_density(vfm_fdn_ir.T, fs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(time_vector, ned_sfm, 'b')\n",
    "plt.plot(time_vector, ned_vfm, 'r')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('NED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Listen to the 2 IRs convolved with a dry signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = Path('../../resources/audio/')\n",
    "input_signal, fs = sf.read(str(audio_path / 'lexicon_dry15.wav'))\n",
    "Audio(str(audio_path / 'lexicon_dry15.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sfm_fdn = conv_binaural(sfm_fdn_ir.T, input_signal, ear_axis=-1)\n",
    "sf.write(str(audio_path / 'lexicon_sfm_fdn.wav'), output_sfm_fdn, fs)\n",
    "Audio(str(audio_path / 'lexicon_sfm_fdn.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vfm_fdn = conv_binaural(vfm_fdn_ir.T, input_signal, ear_axis=-1)\n",
    "sf.write(str(audio_path / 'lexicon_vfm_fdn.wav'), output_vfm_fdn, fs)\n",
    "Audio(str(audio_path / 'lexicon_vfm_fdn.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Binauralise the FDN output by applying the correct IAC filter to the two output channels\n",
    "\n",
    "To get the interaural coherence we desire, we will read an HRTF dataset of a KEMAR mannequin and calculate the IAC from the left and right ear signals, $L(\\omega)$ and $R(\\omega)$ over all azimuth and elevation angles ($M$).\n",
    "\n",
    "$$ \\Phi(\\omega) = \\frac{|\\sum_{m=1}^M L_m(\\omega) R^*_m(\\omega)|}{\\sqrt{\\sum_{m=1}^M |L_m(\\omega)|^2 \\sum_{m=1}^M |R_m(\\omega)|^2}}\n",
    "$$\n",
    "\n",
    "We can then get two filters applied to both FDN output channels, given by:\n",
    "$$ U(\\omega) = \\sqrt{\\frac{1 + \\Phi(\\omega)}{2}} \\qquad V(\\omega) = \\sqrt{\\frac{1 - \\Phi(\\omega)}{2}}$$\n",
    "\n",
    "We can take the inverse DFT to these to get $u(n)$ and $v(n)$ in the time domain. If the two FDN output channels are $r_1(n)$ and $r_2(n)$ respectively, the final output is given by:\n",
    "\n",
    "\\begin{align}\n",
    "b_L(n) = (u * r_1 + v * r_2)(n) \\\\\n",
    "b_R (n) = (u * r_1 - v*r_2) (n)\n",
    "\\end{align}\n",
    "This operation can be written in matrix form as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} b_L (n) \\\\ b_R(n)\\end{bmatrix} = \\begin{bmatrix} u(n) & v(n) \\\\ u(n) & -v(n)\\end{bmatrix} * \\begin{bmatrix}r_1(n) \\\\ r_2(n) \\end{bmatrix}\n",
    "$$\n",
    "Now, the interaural coherence of the output is:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\Phi}(\\omega) &= \\frac{\\mathbb{E}\\left(B_L(\\omega) B_R^*(\\omega) \\right)}{\\mathbb{E}\\left( |B_L(\\omega)|\\right) \\mathbb{E}\\left( |B_R(\\omega)|\\right)} \\\\\n",
    "&= \\frac{\\mathbb{E} \\left[(U(\\omega)R_1(\\omega) + V(\\omega)R_2(\\omega))(U^*(\\omega) R_1^*(\\omega) - V^*(\\omega) R_2^*(\\omega)) \\right]}{\\mathbb{E} \\left( |U(\\omega)|^2 |R_1(\\omega)^2| + |V(\\omega)|^2 |R_2(\\omega)|^2\\right)} \\\\\n",
    "&= \\frac{|U(\\omega)|^2 |\\mathbb{E}\\left(|R_1(\\omega)|^2 \\right) - |V(\\omega)|^2 \\mathbb{E}\\left( |R_2(\\omega)|^2 \\right)}{ |U(\\omega)|^2 |\\mathbb{E}\\left(|R_1(\\omega)|^2 \\right) + |V(\\omega)|^2 \\mathbb{E}\\left(|R_2(\\omega)|^2 \\right)}\n",
    "\\end{align}\n",
    "\n",
    "Now, the two outputs from the FDN are uncorrelated and have the same power, i.e, $\\mathbb{E}\\left[R_1 (\\omega) R_2^*(\\omega) \\right] = 0$ and $\\mathbb{E}\\left[|R_1(\\omega)|^2 \\right] = \\mathbb{E}\\left[ |R_2(\\omega)|^2 \\right] = P(\\omega)$. Therefore, the achieved IAC is:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\Phi}(\\omega) &= \\frac{\\left[\\frac{1 + \\Phi(\\omega)}{2} - \\frac{1 - \\Phi(\\omega)}{2} \\right]P(\\omega)}{\\left[ \\frac{1 + \\Phi(\\omega)}{2} + \\frac{1 - \\Phi(\\omega)}{2} \\right] P(\\omega)}\\\\\n",
    "\\hat{\\Phi}(\\omega) &= \\Phi(\\omega)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Read SONICOM KEMAR small ears SOFA file and get the desired IAC shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_path = '../../resources/KEMAR/KEMAR_Knowl_EarSim_SmallEars/HRTF/HRTF/48kHz/KEMAR_Knowl_EarSim_SmallEars_FreeFieldComp_48kHz.sofa'\n",
    "sofa_file = HRIRSOFAReader(sofa_path)\n",
    "# caculate IAC from the SOFA file\n",
    "des_iac = sofa_file.get_interaural_coherence()\n",
    "num_fft_bins = sofa_file.ir_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### Create the FDN postprocessing filter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = irfft(np.sqrt((1 + des_iac) / 2), n = num_fft_bins)\n",
    "v = irfft(np.sqrt((1 - des_iac) / 2), n = num_fft_bins)\n",
    "\n",
    "# create a matrix with these filters\n",
    "iac_filt_matrix = np.zeros((num_output, num_output, num_fft_bins), dtype=float)\n",
    "iac_filt_matrix[0, ...] = np.vstack((u, u))\n",
    "iac_filt_matrix[1, ...] = np.vstack((v, -v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Run the FDN with postprocessing filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = FDN(fs, num_input, num_output, N, frame_size)\n",
    "\n",
    "fdn.init_io_gains(b, c)\n",
    "fdn.init_direct_gain(direct_gain)\n",
    "fdn.init_delay_line_lengths(delay_lengths)\n",
    "fdn.init_feedback_matrix(FeedbackMatrixType.FILTER_VELVET, sparsity=0.2, num_mixing_stages=1)\n",
    "fdn.init_absorption_gains(des_t60_ms)\n",
    "fdn.init_delay_lines()\n",
    "fdn.init_postprocessing_filters(iac_filt_matrix)\n",
    "\n",
    "bin_vfm_fdn_ir = fdn.process(input_data)\n",
    "output_bin_vfm_fdn = conv_binaural(bin_vfm_fdn_ir.T, input_signal, ear_axis=-1)\n",
    "sf.write(str(audio_path / 'lexicon_bin_vfm_fdn.wav'), output_bin_vfm_fdn, fs)\n",
    "Audio(str(audio_path / 'lexicon_bin_vfm_fdn.wav'))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bin_vfm_fdn_ir.T)\n",
    "plt.plot(np.stack((exp_envelope, -exp_envelope), axis=-1), 'k--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Plot the desired and achieved IACs - low-frequency IAC is off but high-frequency IAC matches better.\n",
    "- FDN output channels are not fully decorrelated to begin with so the math falls apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import pyFDN\n",
    "reload(pyFDN.utils)\n",
    "from pyFDN.utils import interaural_coherence_menzer\n",
    "\n",
    "des_iac_freqs = rfftfreq(num_fft_bins, d = 1.0 / fs)\n",
    "init_iac, est_iac_freqs = interaural_coherence_menzer(vfm_fdn_ir, fs, time_axis=-1, ear_axis=0)\n",
    "est_iac, _ = interaural_coherence_menzer(bin_vfm_fdn_ir, fs, time_axis=-1, ear_axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogx(des_iac_freqs, des_iac)\n",
    "plt.semilogx(est_iac_freqs, init_iac)\n",
    "plt.semilogx(est_iac_freqs, est_iac)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xlim([20, 20000])\n",
    "plt.ylabel('IAC')\n",
    "plt.legend(['Desired', 'Initial', 'Achieved'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
