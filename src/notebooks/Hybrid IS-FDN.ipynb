{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Hybrid image source - FDN reverberation \n",
    "Since the FDN only gives a perceptually plausible late tail, for synthesizing an entire RIR, its output often gets combined\n",
    "with direct paths and early reflections from a different room acoustics simulator. In this notebook, we will use the image-source method to get the impulse response upto 50ms, and then combine it with an output of the FDN using some cross-fading. This will give a more realistic synthesis of the RIR in a shoebox room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import pyroomacoustics as pra\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import NDArray\n",
    "from loguru import logger\n",
    "from scipy.signal.windows import hann\n",
    "from scipy.signal import fftconvolve\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "from pyFDN.fdn import FDN\n",
    "from pyFDN.delay_line import generate_coprime_delay_line_lengths\n",
    "from pyFDN.feedback_matrix import FeedbackMatrixType\n",
    "from pyFDN.utils import ms_to_samps, get_exponential_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Generate room impulse response with image-source method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The desired reverberation time and dimensions of the room\n",
    "fs = 48000\n",
    "rt60 = 0.5  # seconds\n",
    "room_dim = [9, 7.5, 3.5]  # meters\n",
    "\n",
    "# We invert Sabine's formula to obtain the parameters for the ISM simulator\n",
    "e_absorption, max_order = pra.inverse_sabine(rt60, room_dim)\n",
    "\n",
    "# Create the room\n",
    "room = pra.ShoeBox(\n",
    "    room_dim, fs=fs, materials=pra.Material(e_absorption), max_order=20\n",
    ")\n",
    "\n",
    "# place the source in the room\n",
    "room.add_source(position=[2.5, 3.73, 1.76])\n",
    "# add the mic in the room\n",
    "room.add_microphone([6.3, 4.8, 1.2])\n",
    "\n",
    "room.image_source_model()\n",
    "room.compute_rir()\n",
    "im_rir = room.rir[0][0]\n",
    "ir_len = len(im_rir)\n",
    "\n",
    "time_vector = np.arange(0, ir_len/fs, 1.0/fs) \n",
    "time_constant = rt60 / np.log(1000)\n",
    "max_peak_amp = np.max(im_rir)\n",
    "exp_envelope = max_peak_amp * np.exp(-time_vector / time_constant)\n",
    "\n",
    "# # plot the RIR between mic 1 and source 0\n",
    "plt.plot(time_vector, im_rir)\n",
    "plt.plot(time_vector, exp_envelope, 'k--')\n",
    "plt.xlabel('Time')\n",
    "plt.title('Image method RIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Generate room impulse response with feedback delay network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of delay lines\n",
    "N = 16\n",
    "frame_size = 2**7\n",
    "speed_sound = 345\n",
    "max_dist_between_walls = max(room_dim)\n",
    "min_dist_between_walls = min(room_dim)\n",
    "max_delay_line_ms = (max_dist_between_walls) / speed_sound\n",
    "min_delay_line_ms = (min_dist_between_walls) / speed_sound\n",
    "\n",
    "# we want a binaural output\n",
    "num_input = 1\n",
    "num_output = 1\n",
    "\n",
    "# input gains\n",
    "b = np.random.randn(N, num_input)\n",
    "# change coefficients of c so that the columns are orthonormal\n",
    "c = np.random.randn(num_output,N)\n",
    "direct_gain = np.zeros((num_output, num_input))\n",
    "\n",
    "# delay lengths should be co-prime\n",
    "# constrict delay range to be between 50 and 100ms\n",
    "delay_range_ms = np.array([min_dist_between_walls, max_dist_between_walls])\n",
    "delay_lengths = generate_coprime_delay_line_lengths(delay_range_ms, N, fs)\n",
    "logger.info(f'The delay line lengths are {delay_lengths} samples')\n",
    "\n",
    "# create an impulse\n",
    "input_data = np.zeros((num_input, ir_len))\n",
    "input_data[:, 0] = 1.0\n",
    "\n",
    "# desired broadband T60\n",
    "des_t60_ms = rt60 * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdn = FDN(fs, num_input, num_output, N, frame_size)\n",
    "fdn.init_io_gains(b, c)\n",
    "fdn.init_direct_gain(direct_gain)\n",
    "fdn.init_delay_line_lengths(delay_lengths)\n",
    "fdn.init_feedback_matrix(FeedbackMatrixType.SCALAR_RANDOM)\n",
    "fdn.init_absorption_gains(des_t60_ms)\n",
    "fdn.init_delay_lines()\n",
    "\n",
    "fdn_ir = fdn.process(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_vector, room.rir[0][0])\n",
    "plt.plot(time_vector, fdn_ir.T)\n",
    "plt.plot(time_vector, np.max(fdn_ir.T, axis=0) * exp_envelope, 'k--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('FDN RIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Get a hybrid RIR by taking the early reflections from IM and late reverb from FDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rirs(early_rir: NDArray, \n",
    "                 late_rir: NDArray, \n",
    "                 fs: float,\n",
    "                 mixing_time_ms: float = 50, \n",
    "                 xfade_length_ms: float = 20, \n",
    "                 time_axis:int = 0) -> NDArray:\n",
    "    \"\"\"\n",
    "    Combine early and late responses from 2 different RIRs at mixing time with gain matching\n",
    "    Args:\n",
    "        early_rir : RIR from which early response will be taken\n",
    "        late_rir : RIR from which late response will be taken\n",
    "        fs: sampling frequency of the RIRs\n",
    "        mixing_time_ms: time when the RIRs are mixed\n",
    "        xfade_length_ms: length of cross-fade between the two\n",
    "    Returns:\n",
    "        NDArray: the combined RIR\n",
    "    \"\"\"\n",
    "    assert early_rir.shape == late_rir.shape\n",
    "    ir_len_samp = early_rir.shape[0]\n",
    "    num_chans = early_rir.shape[1]\n",
    "\n",
    "    if time_axis != 0:\n",
    "        init_rir = init_rir.T\n",
    "        late_rir = late_rir.T\n",
    "        time_axis = 0\n",
    "    \n",
    "    mixing_time_samp = ms_to_samps(mixing_time_ms, fs)\n",
    "    # create fade in and fade out windows\n",
    "    window_length_samp = ms_to_samps(xfade_length_ms, fs)\n",
    "    window = hann(2 * window_length_samp)\n",
    "    fade_in_win = window[:window_length_samp]\n",
    "    fade_out_win = window[window_length_samp:]\n",
    "    fade_out_win = np.repeat(fade_out_win, num_chans).reshape(window_length_samp, num_chans)\n",
    "    fade_in_win = np.repeat(fade_in_win, num_chans).reshape(window_length_samp, num_chans)\n",
    "\n",
    "    # do gain matching at mixing time\n",
    "    gain_at_mixing_time = np.max(early_rir, axis=time_axis) / np.max(late_rir, axis=time_axis)\n",
    "\n",
    "    # truncate and fade out early response\n",
    "    early_rir[mixing_time_samp - window_length_samp // 2:mixing_time_samp + window_length_samp // 2,:] *= fade_out_win\n",
    "    early_rir[mixing_time_samp + window_length_samp // 2:, :] = np.zeros((ir_len_samp - (mixing_time_samp + window_length_samp // 2), num_chans))\n",
    "    # truncate and fade in late response\n",
    "    late_rir[mixing_time_samp - window_length_samp // 2:mixing_time_samp + window_length_samp // 2,:] *= fade_in_win\n",
    "    late_rir[:mixing_time_samp - window_length_samp // 2, :] = np.zeros((mixing_time_samp - window_length_samp // 2, num_chans))\n",
    "\n",
    "    combined_rir = early_rir + gain_at_mixing_time * late_rir\n",
    "    return combined_rir\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_rir = combine_rirs(im_rir[:, np.newaxis].copy(), fdn_ir.T.copy(), fs, xfade_length_ms=20)\n",
    "plt.figure()\n",
    "plt.plot(time_vector, combined_rir)\n",
    "plt.plot(time_vector, np.max(combined_rir) * exp_envelope, 'k--')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Hybrid RIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "1. Convolve dry output with image method RIR\n",
    "2. Convolve dry output with hybrid RIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = Path('../../resources/audio/')\n",
    "input_signal, fs = sf.read(str(audio_path / 'lexicon_dry15.wav'))\n",
    "Audio(str(audio_path / 'lexicon_dry15.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.convolve with IM rir\n",
    "output_im = fftconvolve(input_signal[:, 0], im_rir)\n",
    "sf.write(str(audio_path / 'lexicon_mono_im.wav'), output_im, fs)\n",
    "Audio(str(audio_path / 'lexicon_mono_im.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. convolve with hybrid RIR\n",
    "output_hyb = fftconvolve(input_signal[:, 0], np.squeeze(combined_rir))\n",
    "sf.write(str(audio_path / 'lexicon_mono_hyb.wav'), output_hyb, fs)\n",
    "Audio(str(audio_path / 'lexicon_mono_hyb.wav'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
